{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load global dataset and \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Path to dataset which we will be using\n",
        "dataset_path = '../../dataset/cleaned_csv_file_500.csv'\n",
        "dataset_sim_path = './sim_cars.csv'\n",
        "index_column_name = 'ID'\n",
        "\n",
        "calculate_csv = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df_cars = pd.read_csv(dataset_path)\n",
        "\n",
        "# Drop any non-numeric columns, in this case, the 'ID' column\n",
        "df_cars = df_cars.drop(columns=[index_column_name])\n",
        "\n",
        "# Calculate the cosine similarity matrix\n",
        "similarity_matrix = cosine_similarity(df_cars)\n",
        "\n",
        "# Convert the similarity matrix to a DataFrame\n",
        "similarity_df = pd.DataFrame(similarity_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save similarity matrix\n",
        "similarity_df[index_column_name] = similarity_df.index + 1\n",
        "similarity_df.set_index(index_column_name,inplace=True)\n",
        "\n",
        "# Save the similarity DataFrame as a CSV file\n",
        "similarity_df.to_csv(dataset_sim_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Median of all values in the DataFrame: 0.9825975796660096\n"
          ]
        }
      ],
      "source": [
        "# Load the similarity matrix from file\n",
        "df = pd.read_csv(dataset_sim_path)\n",
        "\n",
        "# Convert the DataFrame into a single pandas Series\n",
        "melted_df = df.melt()\n",
        "\n",
        "# Calculate the median of all values\n",
        "med = melted_df['value'].median()\n",
        "\n",
        "print(\"Median of all values in the DataFrame:\", med)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6ZNih_8E_JsF"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.980839</td>\n",
              "      <td>0.980839</td>\n",
              "      <td>0.980839</td>\n",
              "      <td>0.980839</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999801</td>\n",
              "      <td>0.999801</td>\n",
              "      <td>0.999801</td>\n",
              "      <td>0.999801</td>\n",
              "      <td>0.999801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>0.980842</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999790</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999801</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.978782</td>\n",
              "      <td>0.978782</td>\n",
              "      <td>0.978782</td>\n",
              "      <td>0.978782</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999801</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.978784</td>\n",
              "      <td>0.978784</td>\n",
              "      <td>0.978784</td>\n",
              "      <td>0.978784</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999801</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.978782</td>\n",
              "      <td>0.978782</td>\n",
              "      <td>0.978782</td>\n",
              "      <td>0.978782</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999801</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.978784</td>\n",
              "      <td>0.978784</td>\n",
              "      <td>0.978784</td>\n",
              "      <td>0.978784</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999801</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.999802</td>\n",
              "      <td>0.978782</td>\n",
              "      <td>0.978782</td>\n",
              "      <td>0.978782</td>\n",
              "      <td>0.978782</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 500 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3         4         5         6   \n",
              "ID                                                                          \n",
              "1    1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  0.980842  \\\n",
              "2    1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  0.980839   \n",
              "3    1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  0.980842   \n",
              "4    1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  0.980842   \n",
              "5    1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  0.980842   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "496  0.999802  0.999801  0.999802  0.999802  0.999802  0.999802  0.978782   \n",
              "497  0.999802  0.999801  0.999802  0.999802  0.999802  0.999802  0.978784   \n",
              "498  0.999802  0.999801  0.999802  0.999802  0.999802  0.999802  0.978782   \n",
              "499  0.999802  0.999801  0.999802  0.999802  0.999802  0.999802  0.978784   \n",
              "500  0.999802  0.999801  0.999802  0.999802  0.999802  0.999802  0.978782   \n",
              "\n",
              "            7         8         9  ...       490       491       492   \n",
              "ID                                 ...                                 \n",
              "1    0.980842  0.980842  0.980842  ...  0.999790  0.999790  0.999790  \\\n",
              "2    0.980839  0.980839  0.980839  ...  0.999790  0.999790  0.999790   \n",
              "3    0.980842  0.980842  0.980842  ...  0.999790  0.999790  0.999790   \n",
              "4    0.980842  0.980842  0.980842  ...  0.999790  0.999790  0.999790   \n",
              "5    0.980842  0.980842  0.980842  ...  0.999790  0.999790  0.999790   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "496  0.978782  0.978782  0.978782  ...  0.999999  0.999999  0.999999   \n",
              "497  0.978784  0.978784  0.978784  ...  0.999999  0.999999  0.999999   \n",
              "498  0.978782  0.978782  0.978782  ...  0.999999  0.999999  0.999999   \n",
              "499  0.978784  0.978784  0.978784  ...  0.999999  0.999999  0.999999   \n",
              "500  0.978782  0.978782  0.978782  ...  0.999999  0.999999  0.999999   \n",
              "\n",
              "          493       494       495       496       497       498       499  \n",
              "ID                                                                         \n",
              "1    0.999790  0.999790  0.999802  0.999802  0.999802  0.999802  0.999802  \n",
              "2    0.999790  0.999790  0.999801  0.999801  0.999801  0.999801  0.999801  \n",
              "3    0.999790  0.999790  0.999802  0.999802  0.999802  0.999802  0.999802  \n",
              "4    0.999790  0.999790  0.999802  0.999802  0.999802  0.999802  0.999802  \n",
              "5    0.999790  0.999790  0.999802  0.999802  0.999802  0.999802  0.999802  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "496  0.999999  0.999999  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
              "497  0.999999  0.999999  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
              "498  0.999999  0.999999  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
              "499  0.999999  0.999999  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
              "500  0.999999  0.999999  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
              "\n",
              "[500 rows x 500 columns]"
            ]
          },
          "execution_count": 314,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['ID'] = df.index + 1\n",
        "df.set_index(index_column_name, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "j_sC1JJuCkxB",
        "outputId": "8bb595a8-9844-4c3b-9c67-5452a49eb9ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.        , 0.99999965, 1.        , ..., 0.99980171, 0.99980165,\n",
              "        0.99980171],\n",
              "       [0.99999965, 1.        , 0.99999965, ..., 0.99980143, 0.99980101,\n",
              "        0.99980143],\n",
              "       [1.        , 0.99999965, 1.        , ..., 0.99980171, 0.99980165,\n",
              "        0.99980171],\n",
              "       ...,\n",
              "       [0.99980171, 0.99980143, 0.99980171, ..., 1.        , 0.99999991,\n",
              "        1.        ],\n",
              "       [0.99980165, 0.99980101, 0.99980165, ..., 0.99999991, 1.        ,\n",
              "        0.99999991],\n",
              "       [0.99980171, 0.99980143, 0.99980171, ..., 1.        , 0.99999991,\n",
              "        1.        ]])"
            ]
          },
          "execution_count": 315,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#converting into a numpy array and fixing the threshold\n",
        "sim_matrix_numpy = np.array(df)\n",
        "sim_matrix_numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3rHuTEe9Gpp9"
      },
      "outputs": [],
      "source": [
        "#keeping only values above threshold and making others as 0.\n",
        "similarity_thres = []\n",
        "for i in sim_matrix_numpy:\n",
        "    f1=[]\n",
        "    for k in i:\n",
        "        if(k==1):\n",
        "            f1.append(0)\n",
        "        elif(k>=med):\n",
        "            f1.append(1)\n",
        "        else:\n",
        "            f1.append(0)\n",
        "    similarity_thres.append(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XE152vqWHD1i"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 500 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4    5    6    7    8    9    ...  490  491  492   \n",
              "0      0    1    0    0    0    0    0    0    0    0  ...    1    1    1  \\\n",
              "1      1    1    1    1    1    1    0    0    0    0  ...    1    1    1   \n",
              "2      0    1    0    0    0    0    0    0    0    0  ...    1    1    1   \n",
              "3      0    1    0    0    0    0    0    0    0    0  ...    1    1    1   \n",
              "4      0    1    0    0    0    0    0    0    0    0  ...    1    1    1   \n",
              "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "495    1    1    1    1    1    1    0    0    0    0  ...    1    1    1   \n",
              "496    1    1    1    1    1    1    0    0    0    0  ...    1    1    1   \n",
              "497    1    1    1    1    1    1    0    0    0    0  ...    1    1    1   \n",
              "498    1    1    1    1    1    1    0    0    0    0  ...    1    1    1   \n",
              "499    1    1    1    1    1    1    0    0    0    0  ...    1    1    1   \n",
              "\n",
              "     493  494  495  496  497  498  499  \n",
              "0      1    1    1    1    1    1    1  \n",
              "1      1    1    1    1    1    1    1  \n",
              "2      1    1    1    1    1    1    1  \n",
              "3      1    1    1    1    1    1    1  \n",
              "4      1    1    1    1    1    1    1  \n",
              "..   ...  ...  ...  ...  ...  ...  ...  \n",
              "495    1    1    0    1    0    1    0  \n",
              "496    1    1    1    0    1    0    1  \n",
              "497    1    1    0    1    0    1    0  \n",
              "498    1    1    1    0    1    0    1  \n",
              "499    1    1    0    1    0    1    0  \n",
              "\n",
              "[500 rows x 500 columns]"
            ]
          },
          "execution_count": 320,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a new dataframe using the boolean matrix\n",
        "sim_bool_matrix_df = pd.DataFrame(similarity_thres)\n",
        "sim_bool_matrix_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5T3QOhLLHMWi"
      },
      "outputs": [],
      "source": [
        "#renaming the columns of the new dataframe.\n",
        "sim_bool_matrix_df.rename(columns={0:\"X1\",1:\"X3\",2:\"X4\",3:\"X6\",4:\"X8\",5:\"X10\",6:\"X13\"},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UJRvDpFRHs2Q"
      },
      "outputs": [],
      "source": [
        "#reindexing to start from 1\n",
        "sim_bool_matrix_df.index = sim_bool_matrix_df.index+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_4MSaZzuHxjF"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X6</th>\n",
              "      <th>X8</th>\n",
              "      <th>X10</th>\n",
              "      <th>X13</th>\n",
              "      <th>DOC2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>X1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>X2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>X3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>X4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>X5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>X6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>X7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>X8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>X9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>X10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>X11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>X12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>X13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>X14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    X1  X3  X4  X6  X8  X10  X13 DOC2\n",
              "1    0   0   0   0   1    1    0   X1\n",
              "2    0   0   1   0   0    0    0   X2\n",
              "3    0   0   0   1   0    0    1   X3\n",
              "4    0   0   0   0   0    0    0   X4\n",
              "5    0   0   0   1   0    0    0   X5\n",
              "6    0   1   0   0   0    0    1   X6\n",
              "7    0   0   1   0   0    0    0   X7\n",
              "8    1   0   0   0   0    1    0   X8\n",
              "9    1   0   1   0   1    0    0   X9\n",
              "10   1   0   0   0   1    0    1  X10\n",
              "11   1   0   1   0   1    0    0  X11\n",
              "12   0   1   0   1   0    0    1  X12\n",
              "13   0   1   0   1   0    1    0  X13\n",
              "14   0   1   0   1   0    0    1  X14"
            ]
          },
          "execution_count": 230,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#creating an index column to get the label in the desired format.\n",
        "sim_bool_matrix_df['DOC'] = (sim_bool_matrix_df.index)\n",
        "sim_bool_matrix_df['X']= \"X\"\n",
        "sim_bool_matrix_df['DOC2'] = sim_bool_matrix_df['X']+sim_bool_matrix_df['DOC'].astype(str)\n",
        "del sim_bool_matrix_df['DOC'],sim_bool_matrix_df['X']\n",
        "\n",
        "sim_bool_matrix_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "colab_type": "code",
        "id": "6iwQ_bUJIVKo",
        "outputId": "4cdd2652-0a95-470c-87de-36c87d794ad1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#plotting the network \n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "stacked = sim_bool_matrix_df.set_index(['DOC2']).stack()\n",
        "stacked = stacked[stacked==1]\n",
        "edges = stacked.index.tolist()\n",
        "#print(il1)\n",
        "#edges\n",
        "G = nx.Graph(edges)\n",
        "Gp = nx.bipartite.projected_graph(G,sim_bool_matrix_df.set_index('DOC2').columns)\n",
        "Gp.edges()\n",
        "#pos = {node:[0, i] for i,node in enumerate(il1['DOC2'])}\n",
        "#pos.update({node:[1, i] for i,node in enumerate(il1['level_1'])})\n",
        "nx.draw(G, with_labels=True)\n",
        "#for p in pos:  # raise text positions\n",
        " #   pos[p][1] += .25\n",
        "#nx.draw_networkx_labels(G,pos=pos)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X6</th>\n",
              "      <th>X8</th>\n",
              "      <th>X10</th>\n",
              "      <th>X13</th>\n",
              "      <th>DOC2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>X1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>X2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>X3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>X4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>X5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>X6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>X7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>X8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>X9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>X10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>X11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>X12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>X13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>X14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    X1  X3  X4  X6  X8  X10  X13 DOC2\n",
              "1    0   0   0   0   1    1    0   X1\n",
              "2    0   0   1   0   0    0    0   X2\n",
              "3    0   0   0   1   0    0    1   X3\n",
              "4    0   0   0   0   0    0    0   X4\n",
              "5    0   0   0   1   0    0    0   X5\n",
              "6    0   1   0   0   0    0    1   X6\n",
              "7    0   0   1   0   0    0    0   X7\n",
              "8    1   0   0   0   0    1    0   X8\n",
              "9    1   0   1   0   1    0    0   X9\n",
              "10   1   0   0   0   1    0    1  X10\n",
              "11   1   0   1   0   1    0    0  X11\n",
              "12   0   1   0   1   0    0    1  X12\n",
              "13   0   1   0   1   0    1    0  X13\n",
              "14   0   1   0   1   0    0    1  X14"
            ]
          },
          "execution_count": 232,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sim_bool_matrix_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Generate random data\n",
        "# # Set a random seed for reproducibility (optional)\n",
        "# np.random.seed(42)\n",
        "\n",
        "# # Generate a 14x7 matrix with random float data\n",
        "# matrix = np.random.rand(14, 7)\n",
        "\n",
        "# # Choose 5 random positions to replace with NaN\n",
        "# num_values_to_remove = 5\n",
        "# rows = np.random.randint(0, matrix.shape[0], num_values_to_remove)\n",
        "# cols = np.random.randint(0, matrix.shape[1], num_values_to_remove)\n",
        "\n",
        "# matrix_backup = matrix.copy()\n",
        "\n",
        "# # Replace the chosen positions with NaN\n",
        "# for row, col in zip(rows, cols):\n",
        "#     matrix[row, col] = np.nan\n",
        "    \n",
        "# # Load the matrix into a pandas DataFrame with the specified column names\n",
        "# column_names = ['X1', 'X3', 'X4', 'X6', 'X8', 'X10', 'X13']\n",
        "\n",
        "# matrix_data = pd.DataFrame(matrix, columns=column_names)\n",
        "\n",
        "# # matrix_data['DOC'] = matrix_data.index + 1\n",
        "\n",
        "# # Print the DataFrame\n",
        "# matrix_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kHzjX2KjJahW"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NTP</th>\n",
              "      <th>PG</th>\n",
              "      <th>DBP</th>\n",
              "      <th>TSFT</th>\n",
              "      <th>2HS1</th>\n",
              "      <th>BMI</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DPF</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>67</td>\n",
              "      <td>33.6</td>\n",
              "      <td>50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>153</td>\n",
              "      <td>90</td>\n",
              "      <td>31</td>\n",
              "      <td>62</td>\n",
              "      <td>43.3</td>\n",
              "      <td>32</td>\n",
              "      <td>0.372</td>\n",
              "      <td>X2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>94</td>\n",
              "      <td>26.6</td>\n",
              "      <td>31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>60</td>\n",
              "      <td>43.1</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>21</td>\n",
              "      <td>80</td>\n",
              "      <td>25.6</td>\n",
              "      <td>30</td>\n",
              "      <td>0.588</td>\n",
              "      <td>X5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>86</td>\n",
              "      <td>28.1</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>117</td>\n",
              "      <td>48</td>\n",
              "      <td>35</td>\n",
              "      <td>45</td>\n",
              "      <td>42.5</td>\n",
              "      <td>32</td>\n",
              "      <td>0.348</td>\n",
              "      <td>X7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11</td>\n",
              "      <td>145</td>\n",
              "      <td>96</td>\n",
              "      <td>33</td>\n",
              "      <td>74</td>\n",
              "      <td>34.9</td>\n",
              "      <td>54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>157</td>\n",
              "      <td>92</td>\n",
              "      <td>34</td>\n",
              "      <td>55</td>\n",
              "      <td>40.5</td>\n",
              "      <td>59</td>\n",
              "      <td>0.501</td>\n",
              "      <td>X9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>72</td>\n",
              "      <td>31</td>\n",
              "      <td>70</td>\n",
              "      <td>35.3</td>\n",
              "      <td>29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>168</td>\n",
              "      <td>74</td>\n",
              "      <td>35</td>\n",
              "      <td>72</td>\n",
              "      <td>38.0</td>\n",
              "      <td>34</td>\n",
              "      <td>0.272</td>\n",
              "      <td>X11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4</td>\n",
              "      <td>88</td>\n",
              "      <td>74</td>\n",
              "      <td>25</td>\n",
              "      <td>88</td>\n",
              "      <td>28.0</td>\n",
              "      <td>34</td>\n",
              "      <td>0.537</td>\n",
              "      <td>X12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>82</td>\n",
              "      <td>31.0</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5</td>\n",
              "      <td>96</td>\n",
              "      <td>62</td>\n",
              "      <td>28</td>\n",
              "      <td>90</td>\n",
              "      <td>23.8</td>\n",
              "      <td>32</td>\n",
              "      <td>0.698</td>\n",
              "      <td>X14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    NTP   PG  DBP  TSFT  2HS1   BMI  AGE    DPF index\n",
              "1     6  148   72    35    67  33.6   50    NaN    X1\n",
              "2     1  153   90    31    62  43.3   32  0.372    X2\n",
              "3     1   85   66    29    94  26.6   31    NaN    X3\n",
              "4     4  137   40    35    60  43.1   33    NaN    X4\n",
              "5     5  116   74    21    80  25.6   30  0.588    X5\n",
              "6     1   89   66    23    86  28.1   21    NaN    X6\n",
              "7     2  117   48    35    45  42.5   32  0.348    X7\n",
              "8    11  145   96    33    74  34.9   54    NaN    X8\n",
              "9     3  157   92    34    55  40.5   59  0.501    X9\n",
              "10   10  115   72    31    70  35.3   29    NaN   X10\n",
              "11   10  168   74    35    72  38.0   34  0.272   X11\n",
              "12    4   88   74    25    88  28.0   34  0.537   X12\n",
              "13    3   88   50    32    82  31.0   26    NaN   X13\n",
              "14    5   96   62    28    90  23.8   32  0.698   X14"
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Reading the original dataset and performing the same to create labels and reindex.\n",
        "dataset = pd.read_csv('SDD.csv')\n",
        "dataset.index = dataset.index+1\n",
        "dataset['DOC'] = (dataset.index)\n",
        "dataset['X']= \"X\"\n",
        "dataset['index'] = dataset['X']+dataset['DOC'].astype(str)\n",
        "del dataset['DOC'],dataset['X']\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "phjMbeAaKTL7"
      },
      "outputs": [],
      "source": [
        "#splitting the null values and creating a new dataframe using the similarity boolean matrix.\n",
        "#dataset.set_index('index',inplace=True)\n",
        "dataset\n",
        "null_data = dataset[dataset.isnull().any(axis=1)]\n",
        "similarity_bool = sim_bool_matrix_df.copy()\n",
        "similarity_bool.set_index('DOC2',inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1EbpcnGaMUNT"
      },
      "outputs": [],
      "source": [
        "#Resetting the index and deleting the index column\n",
        "similarity_bool.reset_index(inplace=True)\n",
        "#del similarity_bool['index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tmlkPGzpMhk7"
      },
      "outputs": [],
      "source": [
        "#del similarity_bool['level_0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "eBmYIJi-Mm5g"
      },
      "outputs": [],
      "source": [
        "## Taking only values above threshold but instead of converting it into 0 & 1 , we are keeping the similarity score as such.\n",
        "similarity_thres1 = []\n",
        "for i in sim_matrix_numpy:\n",
        "    f1=[]\n",
        "    for k in i:\n",
        "        if(k==1):\n",
        "            f1.append(0)\n",
        "        elif(k>=med):\n",
        "            f1.append(k)\n",
        "        else:\n",
        "            f1.append(0)\n",
        "    similarity_thres1.append(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "VGYlU0sqNfcz",
        "outputId": "7ff71e3f-49b0-4ee1-c46f-e1b8e23d19b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       X1     X3     X4     X6     X8    X10    X13 DOC2\n",
            "1   0.000  0.000  0.000  0.000  0.928  0.800  0.000   X1\n",
            "2   0.000  0.000  0.870  0.000  0.000  0.000  0.000   X2\n",
            "3   0.000  0.000  0.000  0.845  0.000  0.000  0.858   X3\n",
            "4   0.000  0.000  0.000  0.000  0.000  0.000  0.000   X4\n",
            "5   0.000  0.000  0.000  0.838  0.000  0.000  0.000   X5\n",
            "6   0.000  0.845  0.000  0.000  0.000  0.000  0.786   X6\n",
            "7   0.000  0.000  0.887  0.000  0.000  0.000  0.000   X7\n",
            "8   0.928  0.000  0.000  0.000  0.000  0.822  0.000   X8\n",
            "9   0.814  0.000  0.844  0.000  0.840  0.000  0.000   X9\n",
            "10  0.800  0.000  0.000  0.000  0.822  0.000  0.823  X10\n",
            "11  0.836  0.000  0.802  0.000  0.836  0.000  0.000  X11\n",
            "12  0.000  0.890  0.000  0.925  0.000  0.000  0.817  X12\n",
            "13  0.000  0.858  0.000  0.785  0.000  0.823  0.000  X13\n",
            "14  0.000  0.897  0.000  0.829  0.000  0.000  0.794  X14\n"
          ]
        }
      ],
      "source": [
        "##sscore is a new dataframe with the above scores.\n",
        "sscore = pd.DataFrame(similarity_thres1)\n",
        "sscore.rename(columns={0:\"X1\",1:\"X3\",2:\"X4\",3:\"X6\",4:\"X8\",5:\"X10\",6:\"X13\"},inplace=True)\n",
        "sscore.index = sscore.index+1\n",
        "sscore['DOC'] = (sscore.index)\n",
        "sscore['X']= \"X\"\n",
        "sscore['DOC2'] = sscore['X']+sscore['DOC'].astype(str)\n",
        "del sscore['DOC'],sscore['X']\n",
        "#sscore.set_index('DOC2',inplace=True)\n",
        "print(sscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "colab_type": "code",
        "id": "yx-mEnbPOBCx",
        "outputId": "b71621eb-732a-44b8-96d2-a7f618919197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DOC2     \n",
            "X1    X8     0.928\n",
            "      X10    0.800\n",
            "X2    X4     0.870\n",
            "X3    X6     0.845\n",
            "      X13    0.858\n",
            "X5    X6     0.838\n",
            "X6    X3     0.845\n",
            "      X13    0.786\n",
            "X7    X4     0.887\n",
            "X8    X1     0.928\n",
            "      X10    0.822\n",
            "X9    X1     0.814\n",
            "      X4     0.844\n",
            "      X8     0.840\n",
            "X10   X1     0.800\n",
            "      X8     0.822\n",
            "      X13    0.823\n",
            "X11   X1     0.836\n",
            "      X4     0.802\n",
            "      X8     0.836\n",
            "X12   X3     0.890\n",
            "      X6     0.925\n",
            "      X13    0.817\n",
            "X13   X3     0.858\n",
            "      X6     0.785\n",
            "      X10    0.823\n",
            "X14   X3     0.897\n",
            "      X6     0.829\n",
            "      X13    0.794\n",
            "dtype: float64\n",
            "[('X1', 'X8'), ('X1', 'X10'), ('X2', 'X4'), ('X3', 'X6'), ('X3', 'X13'), ('X5', 'X6'), ('X6', 'X3'), ('X6', 'X13'), ('X7', 'X4'), ('X8', 'X1'), ('X8', 'X10'), ('X9', 'X1'), ('X9', 'X4'), ('X9', 'X8'), ('X10', 'X1'), ('X10', 'X8'), ('X10', 'X13'), ('X11', 'X1'), ('X11', 'X4'), ('X11', 'X8'), ('X12', 'X3'), ('X12', 'X6'), ('X12', 'X13'), ('X13', 'X3'), ('X13', 'X6'), ('X13', 'X10'), ('X14', 'X3'), ('X14', 'X6'), ('X14', 'X13')]\n",
            "         X1     X3     X4     X6     X8    X10    X13\n",
            "DOC2                                                 \n",
            "X1      NaN    NaN    NaN    NaN  0.928  0.800    NaN\n",
            "X2      NaN    NaN  0.870    NaN    NaN    NaN    NaN\n",
            "X3      NaN    NaN    NaN  0.845    NaN    NaN  0.858\n",
            "X5      NaN    NaN    NaN  0.838    NaN    NaN    NaN\n",
            "X6      NaN  0.845    NaN    NaN    NaN    NaN  0.786\n",
            "X7      NaN    NaN  0.887    NaN    NaN    NaN    NaN\n",
            "X8    0.928    NaN    NaN    NaN    NaN  0.822    NaN\n",
            "X9    0.814    NaN  0.844    NaN  0.840    NaN    NaN\n",
            "X10   0.800    NaN    NaN    NaN  0.822    NaN  0.823\n",
            "X11   0.836    NaN  0.802    NaN  0.836    NaN    NaN\n",
            "X12     NaN  0.890    NaN  0.925    NaN    NaN  0.817\n",
            "X13     NaN  0.858    NaN  0.785    NaN  0.823    NaN\n",
            "X14     NaN  0.897    NaN  0.829    NaN    NaN  0.794\n"
          ]
        }
      ],
      "source": [
        "#doing stacked to only take the values not equal to 0.0 and then unstacking it.\n",
        "stacked1 = sscore.set_index(['DOC2']).stack()\n",
        "#print(stacked1)\n",
        "stacked1 = stacked1[stacked1 != 0.0]\n",
        "print(stacked1)\n",
        "edges = stacked1.index.tolist()\n",
        "print(edges)\n",
        "unstacked = stacked1.unstack()\n",
        "print(unstacked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "colab_type": "code",
        "id": "pRXERRkRQZAI",
        "outputId": "956d9bcd-4682-45f5-a4d8-5fb1763ea712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         X1     X3     X4     X6     X8    X10    X13\n",
            "DOC2                                                 \n",
            "X1      NaN    NaN    NaN    NaN  0.928  0.800    NaN\n",
            "X2      NaN    NaN  0.870    NaN    NaN    NaN    NaN\n",
            "X3      NaN    NaN    NaN  0.845    NaN    NaN  0.858\n",
            "X5      NaN    NaN    NaN  0.838    NaN    NaN    NaN\n",
            "X6      NaN  0.845    NaN    NaN    NaN    NaN  0.786\n",
            "X7      NaN    NaN  0.887    NaN    NaN    NaN    NaN\n",
            "X8    0.928    NaN    NaN    NaN    NaN  0.822    NaN\n",
            "X9    0.814    NaN  0.844    NaN  0.840    NaN    NaN\n",
            "X10   0.800    NaN    NaN    NaN  0.822    NaN  0.823\n",
            "X11   0.836    NaN  0.802    NaN  0.836    NaN    NaN\n",
            "X12     NaN  0.890    NaN  0.925    NaN    NaN  0.817\n",
            "X13     NaN  0.858    NaN  0.785    NaN  0.823    NaN\n",
            "X14     NaN  0.897    NaN  0.829    NaN    NaN  0.794\n",
            "['X1', 'X3', 'X4', 'X6', 'X8', 'X10', 'X13']\n",
            "['X9', 'X11', 'X2', 'X5', 'X14', 'X7', 'X12']\n"
          ]
        }
      ],
      "source": [
        "#creating the incomplete_tuples and complete_tuples from the unstacked dataframe.\n",
        "print(unstacked)\n",
        "##To determine the P value\n",
        "incomplete_tuples = unstacked.columns.to_list()\n",
        "total_tuples = unstacked.index.to_list()\n",
        "complete_tuples = list(set(total_tuples) - set(incomplete_tuples))\n",
        "print(incomplete_tuples)\n",
        "print(complete_tuples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Hn9sxXzeUAXq"
      },
      "outputs": [],
      "source": [
        "#creating a new column in unstacked to house the index values.\n",
        "unstacked['indexed'] = unstacked.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BcI6Umz3UH6M"
      },
      "outputs": [],
      "source": [
        "#filling the unstacked df for NaN\n",
        "unstacked.fillna(0,inplace=True)\n",
        "#del unstacked['index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "colab_type": "code",
        "id": "5y_eQmfdVeIF",
        "outputId": "024fe3f6-e07e-471e-ea21-37f5d4123b53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         X1     X3     X4     X6     X8  X10    X13 indexed\n",
            "DOC2                                                       \n",
            "X2    0.000  0.000  0.870  0.000  0.000  0.0  0.000      X2\n",
            "X5    0.000  0.000  0.000  0.838  0.000  0.0  0.000      X5\n",
            "X7    0.000  0.000  0.887  0.000  0.000  0.0  0.000      X7\n",
            "X9    0.814  0.000  0.844  0.000  0.840  0.0  0.000      X9\n",
            "X11   0.836  0.000  0.802  0.000  0.836  0.0  0.000     X11\n",
            "X12   0.000  0.890  0.000  0.925  0.000  0.0  0.817     X12\n",
            "X14   0.000  0.897  0.000  0.829  0.000  0.0  0.794     X14\n",
            "         X1     X3   X4     X6     X8    X10    X13 indexed\n",
            "DOC2                                                       \n",
            "X1    0.000  0.000  0.0  0.000  0.928  0.800  0.000      X1\n",
            "X3    0.000  0.000  0.0  0.845  0.000  0.000  0.858      X3\n",
            "X6    0.000  0.845  0.0  0.000  0.000  0.000  0.786      X6\n",
            "X8    0.928  0.000  0.0  0.000  0.000  0.822  0.000      X8\n",
            "X10   0.800  0.000  0.0  0.000  0.822  0.000  0.823     X10\n",
            "X13   0.000  0.858  0.0  0.785  0.000  0.823  0.000     X13\n"
          ]
        }
      ],
      "source": [
        "#Keeping only complete neighbours for the incomplete tuples in this \"inc_complete\" dataframe.\n",
        "inc_complete = unstacked[~unstacked['indexed'].isin(incomplete_tuples)]\n",
        "print(inc_complete)\n",
        "#inc_complete\n",
        "#Keeping only incomplete neighbours for the incomplete tuples in this \"inc_complete\" dataframe.\n",
        "inc_incomplete =unstacked[unstacked['indexed'].isin(incomplete_tuples)]\n",
        "print(inc_incomplete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "C_SrVAlwuJPD"
      },
      "outputs": [],
      "source": [
        "#Function to get complete neighbours and their similarities in a dictionary\n",
        "#iterating over the columns in inc_complete, retrieving the complete neighbours for each incomplete tuple and putting them in a dictionary.\n",
        "def incomplete_connection_creator(list_1,dict_1):\n",
        "  listed = []\n",
        "  listed1= []\n",
        "  inc_complete = list_1\n",
        "  incomplete_tuples = dict_1\n",
        "  for column in inc_complete:\n",
        "    name = column\n",
        "    #print(name)\n",
        "    kailai = (list(inc_complete[inc_complete[column] != 0.0].indexed))\n",
        "    kailai1 = (list(inc_complete[inc_complete[column] != 0.0][column]))\n",
        "    #print(kailai)\n",
        "    listed.append(kailai)\n",
        "    listed1.append(kailai1)\n",
        "  #print(listed)\n",
        "  zipped = zip(incomplete_tuples,listed)\n",
        "  zipped1 = zip(incomplete_tuples,listed1)\n",
        "  dict_da = dict(zipped)\n",
        "  dict_db = dict(zipped1)\n",
        "  return dict_da,dict_db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "colab_type": "code",
        "id": "Ugs-cOG055Uj",
        "outputId": "eb9be3dc-aeab-417e-b89d-d5c9ef9230f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'X1': ['X9', 'X11'], 'X3': ['X12', 'X14'], 'X4': ['X2', 'X7', 'X9', 'X11'], 'X6': ['X5', 'X12', 'X14'], 'X8': ['X9', 'X11'], 'X10': [], 'X13': ['X12', 'X14']} \n",
            " {'X1': [0.814, 0.836], 'X3': [0.89, 0.897], 'X4': [0.87, 0.887, 0.844, 0.802], 'X6': [0.838, 0.925, 0.829], 'X8': [0.84, 0.836], 'X10': [], 'X13': [0.817, 0.794]}\n"
          ]
        }
      ],
      "source": [
        "#Getting the complete neighbours and their similarity scores\n",
        "data_dict,data_dict1 = incomplete_connection_creator(inc_complete,incomplete_tuples)\n",
        "print(data_dict,\"\\n\",data_dict1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zkAN9jS_1lw1"
      },
      "outputs": [],
      "source": [
        "##Calculating the p value for the final calculation of node weights.\n",
        "import math\n",
        "def p_value_calc(list_1,dict_1):\n",
        "  incomplete_tuples = list_1\n",
        "  data_dict = dict_1\n",
        "  ##calculating the term (1/Xm)\n",
        "  if len(incomplete_tuples) != 0:\n",
        "    term = 1/(len(incomplete_tuples))\n",
        "  else:\n",
        "    term = 1\n",
        "  ##Summing all the length of values present in the dictionary to get the total number of complete neighbours to the incomplete tuples.\n",
        "  summing = sum(len(v) for v in data_dict.values())\n",
        "  ##math.ceil to Round up to the next whole number for the product of summing and term.\n",
        "  value_1 =math.ceil(term * summing)\n",
        "  return value_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "RflHyhtrISEM",
        "outputId": "e6ba3122-9878-4796-de42-4414217a0dad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "#P-value :\n",
        "p_value = p_value_calc(incomplete_tuples,data_dict)\n",
        "print(p_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vXprWaXj5Zyo"
      },
      "outputs": [],
      "source": [
        "##Creating a dictionary to find out the number of similarity scores associated with each incomplete tuple. We get the length of the dictionary's values for a particular element.\n",
        "def length_getter(list_a,dict_a):\n",
        "  list_length = []\n",
        "  incomplete_tuples = list_a\n",
        "  data_dict1 = dict_a\n",
        "  ## checking if element in incomplete_tuples\n",
        "  for y in incomplete_tuples:\n",
        "    ##for that element we check the similarity scores in data_dict1 dictionary\n",
        "    for y in data_dict1:\n",
        "      ##intializing total to 0\n",
        "      total = 0\n",
        "      #print(\"Element:\",y)\n",
        "      #referencing to fetch the similarity scores -> ex: data_dict1['X1']=[0.814,0.836]\n",
        "      value_list = data_dict1[y]\n",
        "      #print(value_list)\n",
        "      ##Taking their length\n",
        "      count = len(value_list)\n",
        "      total += count\n",
        "      ##appending individual length to a list\n",
        "      list_length.append(total)\n",
        "  #print(list_length)\n",
        "  ##Creating the dictionary which contains the incomplete tuples and their associated value lengths.\n",
        "  zipper=zip(incomplete_tuples,list_length)\n",
        "  data_dict = dict(zipper)\n",
        "  return data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "hiEf86G49FPR",
        "outputId": "1dcafa07-5771-4490-817c-10ca6437fe79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'X1': 2, 'X3': 2, 'X4': 4, 'X6': 3, 'X8': 2, 'X10': 0, 'X13': 2}\n"
          ]
        }
      ],
      "source": [
        "data_dict2 = length_getter(incomplete_tuples,data_dict1)\n",
        "print(data_dict2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Aqj4R91GEkcg"
      },
      "outputs": [],
      "source": [
        "##Calculating the node weights and putting them in a dictionary function\n",
        "def node_weight_calculator(dict_1,dict_2,tuple_1,value1):\n",
        "  list_scores = [] \n",
        "  diction_1 = dict_1\n",
        "  diction_2 = dict_2 \n",
        "  tupled_1 = tuple_1 \n",
        "  p_value = value1\n",
        "  ## iterating over incomplete tuple  present in incomplete_tuples list.\n",
        "  for ij in tupled_1:\n",
        "    #calculating the length of each item in data_dict2\n",
        "    length = (dict_2[ij])\n",
        "    #if length is greater than 0 we calculate the similarity score, else we assign 0\n",
        "    if length>0:\n",
        "      multiply_list = []\n",
        "      #iterate over the length so as to capture all the associate similarity pairs with each incomplete tuple.\n",
        "      for i in range(length):\n",
        "        sim_score = dict_1[ij][i]\n",
        "        ##Calculating the part of node weight from the formula given in the paper.\n",
        "        initial_calc = (1-sim_score)**(1/(p_value))\n",
        "        ##appending to multiply_list the values of initial_calc\n",
        "        multiply_list.append(initial_calc)\n",
        "      #Multiplying all the initial_Calc associated with a element.\n",
        "      weight_1 =np.prod(multiply_list)\n",
        "      ##subtracting 1 from weight_1 as per formula and rounding it to three decimal places to get the final node weight.\n",
        "      final_weight = round(1 - weight_1,3)\n",
        "    else:\n",
        "      #keeping node weight as 0 if there is no similarity\n",
        "      final_weight = 0.0\n",
        "    list_scores.append(final_weight)\n",
        "  ##Creating the final dictionary which contains the incomplete tuple and its associated node weight.\n",
        "  zipper_score = zip(tupled_1,list_scores)\n",
        "  dict_output = dict(zipper_score)\n",
        "  return dict_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "colab_type": "code",
        "id": "jswnvlhE2Wvj",
        "outputId": "9aa6a4b9-b28d-4124-aa78-920e10d48c52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Node weight beofre Imputation Order calc:\n",
            " {'X1': 0.688, 'X3': 0.775, 'X4': 0.923, 'X6': 0.872, 'X8': 0.703, 'X10': 0.0, 'X13': 0.665}\n"
          ]
        }
      ],
      "source": [
        "##Initial Node weight calculator\n",
        "dict_scores = node_weight_calculator(data_dict1,data_dict2,incomplete_tuples,p_value)\n",
        "print(\"Initial Node weight beofre Imputation Order calc:\\n\",dict_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "colab_type": "code",
        "id": "3n9P6cL69stz",
        "outputId": "99951892-1d01-45c8-9e58-65707c5708ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incomplete neighbours to incomplete tuples:\n",
            " {'X1': ['X8', 'X10'], 'X3': ['X6', 'X13'], 'X4': [], 'X6': ['X3', 'X13'], 'X8': ['X1', 'X10'], 'X10': ['X1', 'X8', 'X13'], 'X13': ['X3', 'X6', 'X10']}\n",
            "Incomplete neighbours similarity Score:\n",
            " {'X1': [0.928, 0.8], 'X3': [0.845, 0.858], 'X4': [], 'X6': [0.845, 0.785], 'X8': [0.928, 0.822], 'X10': [0.8, 0.822, 0.823], 'X13': [0.858, 0.786, 0.823]}\n"
          ]
        }
      ],
      "source": [
        "##Incomplete- Incomplete connections and similarities\n",
        "data_dict_inc,data_dict_inc_1 = incomplete_connection_creator(inc_incomplete,incomplete_tuples)\n",
        "print(\"Incomplete neighbours to incomplete tuples:\\n\",data_dict_inc)\n",
        "print(\"Incomplete neighbours similarity Score:\\n\",data_dict_inc_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "colab_type": "code",
        "id": "ipeDow9bBLEs",
        "outputId": "c3571fae-3824-4e71-df50-eedaff62988f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of incomplete neighbours:\n",
            " {'X1': 2, 'X3': 2, 'X4': 0, 'X6': 2, 'X8': 2, 'X10': 3, 'X13': 3}\n",
            "Node Weights: {'X1': 0.688, 'X3': 0.775, 'X4': 0.923, 'X6': 0.872, 'X8': 0.703, 'X10': 0.0, 'X13': 0.665}\n",
            "Removed\n",
            "removed item ['X4']\n",
            "Node Weights input to Greedy Algorithm:\n",
            " {'X1': 0.688, 'X3': 0.775, 'X6': 0.872, 'X8': 0.703, 'X10': 0.0, 'X13': 0.665}\n"
          ]
        }
      ],
      "source": [
        "## Calculating the Node Weight like we did previously for the values.\n",
        "##Creating a dictionary to find out the number of similarity scores associated with each incomplete tuple. We get the length of the dictionary's values for a particular element.\n",
        "data_dict_2 = length_getter(incomplete_tuples,data_dict_inc_1)\n",
        "print(\"Length of incomplete neighbours:\\n\",data_dict_2)\n",
        "\n",
        "##Appending the node weight we have already calculated for these nodes.\n",
        "print(\"Node Weights:\",dict_scores)\n",
        "score_list = []\n",
        "score_list_name = []\n",
        "removed_item =[]\n",
        "for element in incomplete_tuples:\n",
        "  if data_dict_2[element] > 0:\n",
        "    score_list_name.append(element)\n",
        "    score_list.append(dict_scores[element])    \n",
        "  else:\n",
        "    print(\"Removed\")\n",
        "    removed_item.append(element)\n",
        "zip_score_final = zip(score_list_name,score_list)\n",
        "data_final_scores = dict(zip_score_final)\n",
        "print(\"removed item\",removed_item)\n",
        "print(\"Node Weights input to Greedy Algorithm:\\n\",data_final_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "73pyCkbrTHIR"
      },
      "outputs": [],
      "source": [
        "def incomplete_connection_creator1(list_1,dict_1):\n",
        "  listed = []\n",
        "  listed1= []\n",
        "  inc_complete = list_1\n",
        "  incomplete_tuples = dict_1\n",
        "  #print(inc_complete)\n",
        "  #print(incomplete_tuples)\n",
        "  for column in inc_complete:\n",
        "    for column in incomplete_tuples:\n",
        "      name = column\n",
        "      #print(name)\n",
        "      kailai = (list(inc_complete[inc_complete[column] != 0.0].indexed))\n",
        "      kailai1 = (list(inc_complete[inc_complete[column] != 0.0][column]))\n",
        "      #print(kailai)\n",
        "      listed.append(kailai)\n",
        "      listed1.append(kailai1)\n",
        "    #print(\"listed:\",listed)\n",
        "    zipped = zip(incomplete_tuples,listed)\n",
        "    zipped1 = zip(incomplete_tuples,listed1)\n",
        "    dict_da = dict(zipped)\n",
        "    dict_db = dict(zipped1)\n",
        "    return dict_da,dict_db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "mzfRHpiWHlBi",
        "outputId": "f9a3e429-220a-40ca-c216-817fd4c96cae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incomplete Tuple Scores Before Iteration: {'X1': 0.688, 'X3': 0.775, 'X6': 0.872, 'X8': 0.703, 'X10': 0.0, 'X13': 0.665}\n",
            "Node Weight for incomplete tuples stored in a new dictionary: {'X1': 0.688, 'X3': 0.775, 'X6': 0.872, 'X8': 0.703, 'X10': 0.0, 'X13': 0.665}\n",
            "Node With the largest weight: X6\n",
            "Node weight: 0.872\n",
            "Connected pair and score : X3 0.775\n",
            "Connected pair and score : X13 0.665\n",
            "Gain For incomplete tuple: 0.128\n",
            "Updated_incomplete_tuples ['X1', 'X3', 'X8', 'X10', 'X13']\n",
            "Updated complete tuples ['X9', 'X11', 'X2', 'X5', 'X14', 'X7', 'X12', 'X6']\n",
            "data_dict_upd_2:- {'X1': [0.814, 0.836], 'X3': [0.845, 0.89, 0.897], 'X8': [0.84, 0.836], 'X10': [], 'X13': [0.786, 0.817, 0.794]}\n",
            "data_dict_upd_1: {'X1': ['X9', 'X11'], 'X3': ['X6', 'X12', 'X14'], 'X8': ['X9', 'X11'], 'X10': [], 'X13': ['X6', 'X12', 'X14']}\n",
            "X6\n",
            "{'X3': [0.845, 0.89, 0.897], 'X13': [0.786, 0.817, 0.794]}\n",
            "Updated Node weight before Imputation Order calc:\n",
            " {'X3': 0.879, 'X13': 0.799}\n",
            "Appended: {'X3': 0.879, 'X13': 0.799, 'X6': 0.0}\n",
            "Updated Incomplete Tuples scores before proceeding to next iter {'X1': 0.688, 'X3': 0.879, 'X6': 0.0, 'X8': 0.703, 'X10': 0.0, 'X13': 0.799}\n",
            "----------------------------------------------------------------------------------------------------------------------\n",
            "Node With the largest weight: X3\n",
            "Node weight: 0.879\n",
            "Connected pair and score : X6 0.0\n",
            "Connected pair and score : X13 0.799\n",
            "Gain For incomplete tuple: 0.44499999999999995\n",
            "Updated_incomplete_tuples ['X1', 'X8', 'X10', 'X13']\n",
            "Updated complete tuples ['X9', 'X11', 'X2', 'X5', 'X14', 'X7', 'X12', 'X6', 'X3']\n",
            "data_dict_upd_2:- {'X1': [0.814, 0.836], 'X8': [0.84, 0.836], 'X10': [], 'X13': [0.858, 0.786, 0.817, 0.794]}\n",
            "data_dict_upd_1: {'X1': ['X9', 'X11'], 'X8': ['X9', 'X11'], 'X10': [], 'X13': ['X3', 'X6', 'X12', 'X14']}\n",
            "X3\n",
            "{'X13': [0.858, 0.786, 0.817, 0.794]}\n",
            "Updated Node weight before Imputation Order calc:\n",
            " {'X13': 0.895}\n",
            "Appended: {'X13': 0.895, 'X3': 0.0}\n",
            "Updated Incomplete Tuples scores before proceeding to next iter {'X1': 0.688, 'X3': 0.0, 'X6': 0.0, 'X8': 0.703, 'X10': 0.0, 'X13': 0.895}\n",
            "----------------------------------------------------------------------------------------------------------------------\n",
            "Node With the largest weight: X13\n",
            "Node weight: 0.895\n",
            "Connected pair and score : X3 0.0\n",
            "Connected pair and score : X6 0.0\n",
            "Connected pair and score : X10 0.0\n",
            "Gain For incomplete tuple: 1.181\n",
            "Updated_incomplete_tuples ['X1', 'X8', 'X10']\n",
            "Updated complete tuples ['X9', 'X11', 'X2', 'X5', 'X14', 'X7', 'X12', 'X6', 'X3', 'X13']\n",
            "data_dict_upd_2:- {'X1': [0.814, 0.836], 'X8': [0.84, 0.836], 'X10': [0.823]}\n",
            "data_dict_upd_1: {'X1': ['X9', 'X11'], 'X8': ['X9', 'X11'], 'X10': ['X13']}\n",
            "X13\n",
            "{'X10': [0.823]}\n",
            "Updated Node weight before Imputation Order calc:\n",
            " {'X10': 0.439}\n",
            "Appended: {'X10': 0.439, 'X13': 0.0}\n",
            "Updated Incomplete Tuples scores before proceeding to next iter {'X1': 0.688, 'X3': 0.0, 'X6': 0.0, 'X8': 0.703, 'X10': 0.439, 'X13': 0.0}\n",
            "----------------------------------------------------------------------------------------------------------------------\n",
            "Node With the largest weight: X8\n",
            "Node weight: 0.703\n",
            "Connected pair and score : X1 0.688\n",
            "Connected pair and score : X10 0.439\n",
            "Gain For incomplete tuple: 0.124\n",
            "Updated_incomplete_tuples ['X1', 'X10']\n",
            "Updated complete tuples ['X9', 'X11', 'X2', 'X5', 'X14', 'X7', 'X12', 'X6', 'X3', 'X13', 'X8']\n",
            "data_dict_upd_2:- {'X1': [0.928, 0.814, 0.836], 'X10': [0.822, 0.823]}\n",
            "data_dict_upd_1: {'X1': ['X8', 'X9', 'X11'], 'X10': ['X8', 'X13']}\n",
            "X8\n",
            "{'X1': [0.928, 0.814, 0.836], 'X10': [0.822, 0.823]}\n",
            "Updated Node weight before Imputation Order calc:\n",
            " {'X1': 0.87, 'X10': 0.684}\n",
            "Appended: {'X1': 0.87, 'X10': 0.684, 'X8': 0.0}\n",
            "Updated Incomplete Tuples scores before proceeding to next iter {'X1': 0.87, 'X3': 0.0, 'X6': 0.0, 'X8': 0.0, 'X10': 0.684, 'X13': 0.0}\n",
            "----------------------------------------------------------------------------------------------------------------------\n",
            "Node With the largest weight: X1\n",
            "Node weight: 0.87\n",
            "Connected pair and score : X8 0.0\n",
            "Connected pair and score : X10 0.684\n",
            "Gain For incomplete tuple: 0.585\n",
            "Updated_incomplete_tuples ['X10']\n",
            "Updated complete tuples ['X9', 'X11', 'X2', 'X5', 'X14', 'X7', 'X12', 'X6', 'X3', 'X13', 'X8', 'X1']\n",
            "data_dict_upd_2:- {'X10': [0.8, 0.822, 0.823]}\n",
            "data_dict_upd_1: {'X10': ['X1', 'X8', 'X13']}\n",
            "X1\n",
            "{'X10': [0.8, 0.822, 0.823]}\n",
            "Updated Node weight before Imputation Order calc:\n",
            " {'X10': 0.815}\n",
            "Appended: {'X10': 0.815, 'X1': 0.0}\n",
            "Updated Incomplete Tuples scores before proceeding to next iter {'X1': 0.0, 'X3': 0.0, 'X6': 0.0, 'X8': 0.0, 'X10': 0.815, 'X13': 0.0}\n",
            "----------------------------------------------------------------------------------------------------------------------\n",
            "Node With the largest weight: X10\n",
            "Node weight: 0.815\n",
            "Connected pair and score : X1 0.0\n",
            "Connected pair and score : X8 0.0\n",
            "Connected pair and score : X13 0.0\n",
            "Gain For incomplete tuple: 1.052\n",
            "Updated_incomplete_tuples []\n",
            "Updated complete tuples ['X9', 'X11', 'X2', 'X5', 'X14', 'X7', 'X12', 'X6', 'X3', 'X13', 'X8', 'X1', 'X10']\n",
            "data_dict_upd_2:- {}\n",
            "data_dict_upd_1: {}\n",
            "X10\n",
            "{}\n",
            "Updated Node weight before Imputation Order calc:\n",
            " {}\n",
            "Appended: {'X10': 0.0}\n",
            "Updated Incomplete Tuples scores before proceeding to next iter {'X1': 0.0, 'X3': 0.0, 'X6': 0.0, 'X8': 0.0, 'X10': 0.0, 'X13': 0.0}\n",
            "----------------------------------------------------------------------------------------------------------------------\n",
            "Final Greedy Imputation order is ['X6', 'X3', 'X13', 'X8', 'X1', 'X10']\n",
            "final_order ['X4', 'X6', 'X3', 'X13', 'X8', 'X1', 'X10']\n",
            "[4, 6, 3, 13, 8, 1, 10]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "GREEDY ALGORITHM TO FIND THE IMPUTATION ORDER\n",
        "STEP 1: Find Node with Largest Weight. Keep it as the starting point\n",
        "STEP 2: Calculate the Filling Gain to make it a complete Neighbour.\n",
        "STEP 3: If the imputed Node, contains any connections to incomplete tuples then update their node weights by considering the imputed node\n",
        "        as a completed neighbour.\n",
        "STEP 4: Repeat this process untill all the incomplete tuples are imputed.\n",
        "'''\n",
        "\n",
        "##STEP 1: Find Node with Largest Weight. Keep it as the starting point\n",
        "#Getting the data_final_scores\n",
        "incomplete_tuples_score = data_final_scores\n",
        "print(\"Incomplete Tuple Scores Before Iteration:\",incomplete_tuples_score)\n",
        "#updated_incomplete_tuples = incomplete_tuples.copy()\n",
        "updated_incomplete_tuples = score_list_name.copy()\n",
        "updated_complete_tuples = complete_tuples.copy()\n",
        "final_greedy_order = []\n",
        "print(\"Node Weight for incomplete tuples stored in a new dictionary:\",incomplete_tuples_score)\n",
        "################################################################################################\n",
        "##########################:\n",
        "for i in range(len(incomplete_tuples_score)):  \n",
        "  max_value = max(incomplete_tuples_score, key=incomplete_tuples_score.get)\n",
        "  print(\"Node With the largest weight:\",max_value)\n",
        "  print(\"Node weight:\",incomplete_tuples_score[max_value])\n",
        "  ##Calculate the Filling Gain\n",
        "  #print(\"X is:\",data_dict_2[max_value])\n",
        "  #print(\"Pairs are :\",data_dict_inc[max_value])\n",
        "  if max_value in data_dict_2:\n",
        "    list_score_holder = []\n",
        "    final_gain_score_holder = []\n",
        "    for i in range(data_dict_2[max_value]):\n",
        "      w_label = data_dict_inc[max_value][i]\n",
        "      w_score = incomplete_tuples_score[w_label]\n",
        "      print(\"Connected pair and score :\",w_label,w_score)\n",
        "      list_score_holder.append(w_score)\n",
        "      #print(data_dict_inc_1[max_value][i])\n",
        "      #print(p_value)\n",
        "      w_difference = round((incomplete_tuples_score[max_value] - list_score_holder[i]),3)\n",
        "      #print(data_dict_inc_1[max_value][i])\n",
        "      w_second_part =round((1-data_dict_inc_1[max_value][i])**(1/p_value),3)\n",
        "      gain = round(((w_difference)*(1-w_second_part)),3)\n",
        "      #print(w_difference)\n",
        "      #print(w_second_part)\n",
        "      #print(\"Gain is :\",gain)\n",
        "      final_gain_score_holder.append(gain)\n",
        "      #print(\"Final Gain calculated:\",final_gain_score_holder)\n",
        "    gain_for_element = sum(final_gain_score_holder)\n",
        "    print(\"Gain For incomplete tuple:\",gain_for_element )\n",
        "    updated_incomplete_tuples.remove(max_value)\n",
        "    updated_complete_tuples.append(max_value)\n",
        "    print(\"Updated_incomplete_tuples\",updated_incomplete_tuples)\n",
        "    print(\"Updated complete tuples\",updated_complete_tuples)\n",
        "    inc_complete_updated = unstacked[~unstacked['indexed'].isin(updated_incomplete_tuples)]\n",
        "    data_dict_upd_1,data_dict_upd_2 = incomplete_connection_creator1(inc_complete_updated,updated_incomplete_tuples)\n",
        "    upd_p_value = p_value_calc(updated_incomplete_tuples,data_dict_upd_1)\n",
        "    data_dict_upd = length_getter(updated_incomplete_tuples,data_dict_upd_2)\n",
        "    print(\"data_dict_upd_2:-\",data_dict_upd_2)\n",
        "    print(\"data_dict_upd_1:\",data_dict_upd_1)\n",
        "    print(max_value)\n",
        "    new_dict = { k : v for k,v in data_dict_upd_1.items() if max_value in v}\n",
        "    new_dict_scores = []\n",
        "    new_dict_key = []\n",
        "    for key,value in new_dict.items():\n",
        "      new_value = data_dict_upd_2[key]\n",
        "      new_dict_scores.append(new_value)\n",
        "      new_key = key\n",
        "      new_dict_key.append(key)\n",
        "    new_zipped = zip(new_dict_key,new_dict_scores)\n",
        "    new_dict_input = dict(new_zipped)\n",
        "    print(new_dict_input)\n",
        "    dict_scores_upd = node_weight_calculator(new_dict_input,data_dict_upd,new_dict_key,p_value)\n",
        "    print(\"Updated Node weight before Imputation Order calc:\\n\",dict_scores_upd)\n",
        "    dict_scores_upd.update({max_value:0.0})\n",
        "    final_greedy_order.append(max_value)\n",
        "    print(\"Appended:\",dict_scores_upd)\n",
        "    incomplete_tuples_score.update(dict_scores_upd)\n",
        "    print(\"Updated Incomplete Tuples scores before proceeding to next iter\",incomplete_tuples_score)\n",
        "    print(\"----------------------------------------------------------------------------------------------------------------------\")\n",
        "print(\"Final Greedy Imputation order is\",final_greedy_order)\n",
        "\n",
        "##Creating the final order for feeding to the KNN\n",
        "final_order = removed_item+final_greedy_order\n",
        "print(\"final_order\",final_order)\n",
        "final_greedy_impute = []\n",
        "for a in final_order:\n",
        "  str_name = str(a)\n",
        "  strip_name = str_name[1:]\n",
        "  final_greedy_impute.append(int(strip_name))\n",
        "print(final_greedy_impute)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "colab_type": "code",
        "id": "k9lE2mPP8GQv",
        "outputId": "f15773e6-1361-45e6-9b07-e8e33264b665"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NTP</th>\n",
              "      <th>PG</th>\n",
              "      <th>DBP</th>\n",
              "      <th>TSFT</th>\n",
              "      <th>2HS1</th>\n",
              "      <th>BMI</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DPF</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>67</td>\n",
              "      <td>33.6</td>\n",
              "      <td>50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>153</td>\n",
              "      <td>90</td>\n",
              "      <td>31</td>\n",
              "      <td>62</td>\n",
              "      <td>43.3</td>\n",
              "      <td>32</td>\n",
              "      <td>0.372</td>\n",
              "      <td>X2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>94</td>\n",
              "      <td>26.6</td>\n",
              "      <td>31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>60</td>\n",
              "      <td>43.1</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>21</td>\n",
              "      <td>80</td>\n",
              "      <td>25.6</td>\n",
              "      <td>30</td>\n",
              "      <td>0.588</td>\n",
              "      <td>X5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>86</td>\n",
              "      <td>28.1</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>117</td>\n",
              "      <td>48</td>\n",
              "      <td>35</td>\n",
              "      <td>45</td>\n",
              "      <td>42.5</td>\n",
              "      <td>32</td>\n",
              "      <td>0.348</td>\n",
              "      <td>X7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11</td>\n",
              "      <td>145</td>\n",
              "      <td>96</td>\n",
              "      <td>33</td>\n",
              "      <td>74</td>\n",
              "      <td>34.9</td>\n",
              "      <td>54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>157</td>\n",
              "      <td>92</td>\n",
              "      <td>34</td>\n",
              "      <td>55</td>\n",
              "      <td>40.5</td>\n",
              "      <td>59</td>\n",
              "      <td>0.501</td>\n",
              "      <td>X9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>72</td>\n",
              "      <td>31</td>\n",
              "      <td>70</td>\n",
              "      <td>35.3</td>\n",
              "      <td>29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>168</td>\n",
              "      <td>74</td>\n",
              "      <td>35</td>\n",
              "      <td>72</td>\n",
              "      <td>38.0</td>\n",
              "      <td>34</td>\n",
              "      <td>0.272</td>\n",
              "      <td>X11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4</td>\n",
              "      <td>88</td>\n",
              "      <td>74</td>\n",
              "      <td>25</td>\n",
              "      <td>88</td>\n",
              "      <td>28.0</td>\n",
              "      <td>34</td>\n",
              "      <td>0.537</td>\n",
              "      <td>X12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>82</td>\n",
              "      <td>31.0</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5</td>\n",
              "      <td>96</td>\n",
              "      <td>62</td>\n",
              "      <td>28</td>\n",
              "      <td>90</td>\n",
              "      <td>23.8</td>\n",
              "      <td>32</td>\n",
              "      <td>0.698</td>\n",
              "      <td>X14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    NTP   PG  DBP  TSFT  2HS1   BMI  AGE    DPF index\n",
              "1     6  148   72    35    67  33.6   50    NaN    X1\n",
              "2     1  153   90    31    62  43.3   32  0.372    X2\n",
              "3     1   85   66    29    94  26.6   31    NaN    X3\n",
              "4     4  137   40    35    60  43.1   33    NaN    X4\n",
              "5     5  116   74    21    80  25.6   30  0.588    X5\n",
              "6     1   89   66    23    86  28.1   21    NaN    X6\n",
              "7     2  117   48    35    45  42.5   32  0.348    X7\n",
              "8    11  145   96    33    74  34.9   54    NaN    X8\n",
              "9     3  157   92    34    55  40.5   59  0.501    X9\n",
              "10   10  115   72    31    70  35.3   29    NaN   X10\n",
              "11   10  168   74    35    72  38.0   34  0.272   X11\n",
              "12    4   88   74    25    88  28.0   34  0.537   X12\n",
              "13    3   88   50    32    82  31.0   26    NaN   X13\n",
              "14    5   96   62    28    90  23.8   32  0.698   X14"
            ]
          },
          "execution_count": 257,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "############################\n",
        "#KNN Modelling Approach\n",
        "dataset_1 = dataset.copy()\n",
        "dataset_1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MOGkEr2WSbS7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NTP</th>\n",
              "      <th>PG</th>\n",
              "      <th>DBP</th>\n",
              "      <th>TSFT</th>\n",
              "      <th>2HS1</th>\n",
              "      <th>BMI</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DPF</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>X1</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>67</td>\n",
              "      <td>33.6</td>\n",
              "      <td>50</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X2</th>\n",
              "      <td>1</td>\n",
              "      <td>153</td>\n",
              "      <td>90</td>\n",
              "      <td>31</td>\n",
              "      <td>62</td>\n",
              "      <td>43.3</td>\n",
              "      <td>32</td>\n",
              "      <td>0.372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X3</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>94</td>\n",
              "      <td>26.6</td>\n",
              "      <td>31</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X4</th>\n",
              "      <td>4</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>60</td>\n",
              "      <td>43.1</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>21</td>\n",
              "      <td>80</td>\n",
              "      <td>25.6</td>\n",
              "      <td>30</td>\n",
              "      <td>0.588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X6</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>86</td>\n",
              "      <td>28.1</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X7</th>\n",
              "      <td>2</td>\n",
              "      <td>117</td>\n",
              "      <td>48</td>\n",
              "      <td>35</td>\n",
              "      <td>45</td>\n",
              "      <td>42.5</td>\n",
              "      <td>32</td>\n",
              "      <td>0.348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X8</th>\n",
              "      <td>11</td>\n",
              "      <td>145</td>\n",
              "      <td>96</td>\n",
              "      <td>33</td>\n",
              "      <td>74</td>\n",
              "      <td>34.9</td>\n",
              "      <td>54</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X9</th>\n",
              "      <td>3</td>\n",
              "      <td>157</td>\n",
              "      <td>92</td>\n",
              "      <td>34</td>\n",
              "      <td>55</td>\n",
              "      <td>40.5</td>\n",
              "      <td>59</td>\n",
              "      <td>0.501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X10</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>72</td>\n",
              "      <td>31</td>\n",
              "      <td>70</td>\n",
              "      <td>35.3</td>\n",
              "      <td>29</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X11</th>\n",
              "      <td>10</td>\n",
              "      <td>168</td>\n",
              "      <td>74</td>\n",
              "      <td>35</td>\n",
              "      <td>72</td>\n",
              "      <td>38.0</td>\n",
              "      <td>34</td>\n",
              "      <td>0.272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X12</th>\n",
              "      <td>4</td>\n",
              "      <td>88</td>\n",
              "      <td>74</td>\n",
              "      <td>25</td>\n",
              "      <td>88</td>\n",
              "      <td>28.0</td>\n",
              "      <td>34</td>\n",
              "      <td>0.537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X13</th>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>82</td>\n",
              "      <td>31.0</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X14</th>\n",
              "      <td>5</td>\n",
              "      <td>96</td>\n",
              "      <td>62</td>\n",
              "      <td>28</td>\n",
              "      <td>90</td>\n",
              "      <td>23.8</td>\n",
              "      <td>32</td>\n",
              "      <td>0.698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       NTP   PG  DBP  TSFT  2HS1   BMI  AGE    DPF\n",
              "index                                             \n",
              "X1       6  148   72    35    67  33.6   50    NaN\n",
              "X2       1  153   90    31    62  43.3   32  0.372\n",
              "X3       1   85   66    29    94  26.6   31    NaN\n",
              "X4       4  137   40    35    60  43.1   33    NaN\n",
              "X5       5  116   74    21    80  25.6   30  0.588\n",
              "X6       1   89   66    23    86  28.1   21    NaN\n",
              "X7       2  117   48    35    45  42.5   32  0.348\n",
              "X8      11  145   96    33    74  34.9   54    NaN\n",
              "X9       3  157   92    34    55  40.5   59  0.501\n",
              "X10     10  115   72    31    70  35.3   29    NaN\n",
              "X11     10  168   74    35    72  38.0   34  0.272\n",
              "X12      4   88   74    25    88  28.0   34  0.537\n",
              "X13      3   88   50    32    82  31.0   26    NaN\n",
              "X14      5   96   62    28    90  23.8   32  0.698"
            ]
          },
          "execution_count": 258,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_1.set_index('index',inplace=True)\n",
        "dataset_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "K3vu1tbRteJM",
        "outputId": "707de118-c6ba-4e1b-eb28-a0c56e352503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Converted into a Numpy Array:\n",
            " [[  6.    148.     72.     35.     67.     33.6    50.        nan]\n",
            " [  1.    153.     90.     31.     62.     43.3    32.      0.372]\n",
            " [  1.     85.     66.     29.     94.     26.6    31.        nan]\n",
            " [  4.    137.     40.     35.     60.     43.1    33.        nan]\n",
            " [  5.    116.     74.     21.     80.     25.6    30.      0.588]\n",
            " [  1.     89.     66.     23.     86.     28.1    21.        nan]\n",
            " [  2.    117.     48.     35.     45.     42.5    32.      0.348]\n",
            " [ 11.    145.     96.     33.     74.     34.9    54.        nan]\n",
            " [  3.    157.     92.     34.     55.     40.5    59.      0.501]\n",
            " [ 10.    115.     72.     31.     70.     35.3    29.        nan]\n",
            " [ 10.    168.     74.     35.     72.     38.     34.      0.272]\n",
            " [  4.     88.     74.     25.     88.     28.     34.      0.537]\n",
            " [  3.     88.     50.     32.     82.     31.     26.        nan]\n",
            " [  5.     96.     62.     28.     90.     23.8    32.      0.698]]\n",
            "\n",
            "Zeroes Array\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            "No of Rows are 14\n",
            "No of Cols are 8\n",
            "{1: array([  6. , 148. ,  72. ,  35. ,  67. ,  33.6,  50. ,   nan]), 3: array([ 1. , 85. , 66. , 29. , 94. , 26.6, 31. ,  nan]), 4: array([  4. , 137. ,  40. ,  35. ,  60. ,  43.1,  33. ,   nan]), 6: array([ 1. , 89. , 66. , 23. , 86. , 28.1, 21. ,  nan]), 8: array([ 11. , 145. ,  96. ,  33. ,  74. ,  34.9,  54. ,   nan]), 10: array([ 10. , 115. ,  72. ,  31. ,  70. ,  35.3,  29. ,   nan]), 13: array([ 3., 88., 50., 32., 82., 31., 26., nan])}\n",
            "[(4, array([  4. , 137. ,  40. ,  35. ,  60. ,  43.1,  33. ,   nan])), (6, array([ 1. , 89. , 66. , 23. , 86. , 28.1, 21. ,  nan])), (3, array([ 1. , 85. , 66. , 29. , 94. , 26.6, 31. ,  nan])), (13, array([ 3., 88., 50., 32., 82., 31., 26., nan])), (8, array([ 11. , 145. ,  96. ,  33. ,  74. ,  34.9,  54. ,   nan])), (1, array([  6. , 148. ,  72. ,  35. ,  67. ,  33.6,  50. ,   nan])), (10, array([ 10. , 115. ,  72. ,  31. ,  70. ,  35.3,  29. ,   nan]))]\n",
            "[4, 6, 3, 13, 8, 1, 10]\n",
            "[array([  4. , 137. ,  40. ,  35. ,  60. ,  43.1,  33. ,   nan]), array([ 1. , 89. , 66. , 23. , 86. , 28.1, 21. ,  nan]), array([ 1. , 85. , 66. , 29. , 94. , 26.6, 31. ,  nan]), array([ 3., 88., 50., 32., 82., 31., 26., nan]), array([ 11. , 145. ,  96. ,  33. ,  74. ,  34.9,  54. ,   nan]), array([  6. , 148. ,  72. ,  35. ,  67. ,  33.6,  50. ,   nan]), array([ 10. , 115. ,  72. ,  31. ,  70. ,  35.3,  29. ,   nan])]\n",
            "4\n",
            "Imputed Data After Filling the Complete Rows:\n",
            " [[  0.      0.      0.      0.      0.      0.      0.      0.   ]\n",
            " [  1.    153.     90.     31.     62.     43.3    32.      0.372]\n",
            " [  0.      0.      0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.      0.      0.   ]\n",
            " [  5.    116.     74.     21.     80.     25.6    30.      0.588]\n",
            " [  0.      0.      0.      0.      0.      0.      0.      0.   ]\n",
            " [  2.    117.     48.     35.     45.     42.5    32.      0.348]\n",
            " [  0.      0.      0.      0.      0.      0.      0.      0.   ]\n",
            " [  3.    157.     92.     34.     55.     40.5    59.      0.501]\n",
            " [  0.      0.      0.      0.      0.      0.      0.      0.   ]\n",
            " [ 10.    168.     74.     35.     72.     38.     34.      0.272]\n",
            " [  4.     88.     74.     25.     88.     28.     34.      0.537]\n",
            " [  0.      0.      0.      0.      0.      0.      0.      0.   ]\n",
            " [  5.     96.     62.     28.     90.     23.8    32.      0.698]]\n",
            "Incomplete Rows in the Array\n",
            " [array([  4. , 137. ,  40. ,  35. ,  60. ,  43.1,  33. ,   nan]), array([ 1. , 89. , 66. , 23. , 86. , 28.1, 21. ,  nan]), array([ 1. , 85. , 66. , 29. , 94. , 26.6, 31. ,  nan]), array([ 3., 88., 50., 32., 82., 31., 26., nan]), array([ 11. , 145. ,  96. ,  33. ,  74. ,  34.9,  54. ,   nan]), array([  6. , 148. ,  72. ,  35. ,  67. ,  33.6,  50. ,   nan]), array([ 10. , 115. ,  72. ,  31. ,  70. ,  35.3,  29. ,   nan])]\n",
            "Distance Before Sort: [2786.04, 2509.25, 694.36, 3813.76, 2324.01, 4670.01, 3488.49]\n",
            "Sorted Dictionary [(2, 694.36), (4, 2324.01), (1, 2509.25), (0, 2786.04), (6, 3488.49), (3, 3813.76), (5, 4670.01)]\n",
            "K Cluster Dictionary [(2, 694.36), (4, 2324.01), (1, 2509.25), (0, 2786.04), (6, 3488.49)]\n",
            "Retrieved K Distances [694.36, 2324.01, 2509.25, 2786.04, 3488.49]\n",
            "Final_Weight: [0.49412772355923756, 0.14763384242348018, 0.13673509061695416, 0.12315061023193932, 0.09835273316838869]\n",
            "-----------------------------------------------------------------------------------------\n",
            "Final Imputed value: 0.407\n",
            "-----------------------------------------------------------------------------------------\n",
            "Distance Before Sort: [5664.04, 936.25, 3262.3599999999997, 7983.76, 6993.01, 251.01, 261.49, 4178.0]\n",
            "Sorted Dictionary [(5, 251.01), (6, 261.49), (1, 936.25), (2, 3262.3599999999997), (7, 4178.0), (0, 5664.04), (4, 6993.01), (3, 7983.76)]\n",
            "K Cluster Dictionary [(5, 251.01), (6, 261.49), (1, 936.25), (2, 3262.3599999999997), (7, 4178.0)]\n",
            "Retrieved K Distances [251.01, 261.49, 936.25, 3262.3599999999997, 4178.0]\n",
            "Final_Weight: [0.4228251730888043, 0.4058791796895513, 0.1133600498766577, 0.032532690045556215, 0.02540290729943053]\n",
            "-----------------------------------------------------------------------------------------\n",
            "Final Imputed value: 0.599\n",
            "-----------------------------------------------------------------------------------------\n",
            "Distance Before Sort: [6507.889999999999, 1303.0, 4039.81, 8387.21, 7692.96, 144.95999999999998, 178.84, 4857.25, 218.25]\n",
            "Sorted Dictionary [(5, 144.95999999999998), (6, 178.84), (8, 218.25), (1, 1303.0), (2, 4039.81), (7, 4857.25), (0, 6507.889999999999), (4, 7692.96), (3, 8387.21)]\n",
            "K Cluster Dictionary [(5, 144.95999999999998), (6, 178.84), (8, 218.25), (1, 1303.0), (2, 4039.81)]\n",
            "Retrieved K Distances [144.95999999999998, 178.84, 218.25, 1303.0, 4039.81]\n",
            "Final_Weight: [0.3814052437754243, 0.30915066057753016, 0.253326479439567, 0.04243169926146239, 0.01368591694601615]\n",
            "-----------------------------------------------------------------------------------------\n",
            "Final Imputed value: 0.602\n",
            "-----------------------------------------------------------------------------------------\n",
            "Distance Before Sort: [6417.29, 1534.16, 2392.25, 8437.25, 7247.0, 735.0, 379.84, 3190.41, 391.40999999999997, 466.36]\n",
            "Sorted Dictionary [(6, 379.84), (8, 391.40999999999997), (9, 466.36), (5, 735.0), (1, 1534.16), (2, 2392.25), (7, 3190.41), (0, 6417.29), (4, 7247.0), (3, 8437.25)]\n",
            "K Cluster Dictionary [(6, 379.84), (8, 391.40999999999997), (9, 466.36), (5, 735.0), (1, 1534.16)]\n",
            "Retrieved K Distances [379.84, 391.40999999999997, 466.36, 735.0, 1534.16]\n",
            "Final_Weight: [0.28174604073744186, 0.27341768507117836, 0.22947597588495994, 0.1456032872295373, 0.06975701107688241]\n",
            "-----------------------------------------------------------------------------------------\n",
            "Final Imputed value: 0.618\n",
            "-----------------------------------------------------------------------------------------\n",
            "Distance Before Sort: [902.56, 2203.49, 4555.76, 642.36, 1431.6100000000001, 4489.61, 4481.21, 3957.24, 5515.24, 5613.889999999999, 6293.21]\n",
            "Sorted Dictionary [(3, 642.36), (0, 902.56), (4, 1431.6100000000001), (1, 2203.49), (7, 3957.24), (6, 4481.21), (5, 4489.61), (2, 4555.76), (8, 5515.24), (9, 5613.889999999999), (10, 6293.21)]\n",
            "K Cluster Dictionary [(3, 642.36), (0, 902.56), (4, 1431.6100000000001), (1, 2203.49), (7, 3957.24)]\n",
            "Retrieved K Distances [642.36, 902.56, 1431.6100000000001, 2203.49, 3957.24]\n",
            "Final_Weight: [0.382518717652591, 0.27224198221870943, 0.1716352382781053, 0.11151161270135938, 0.06209244914923491]\n",
            "-----------------------------------------------------------------------------------------\n",
            "Final Imputed value: 0.43\n",
            "-----------------------------------------------------------------------------------------\n",
            "Distance Before Sort: [833.0899999999999, 1858.0, 2440.21, 763.61, 720.36, 4436.36, 3803.04, 1577.25, 4918.25, 5205.0, 4909.76, 680.69]\n",
            "Sorted Dictionary [(11, 680.69), (4, 720.36), (3, 763.61), (0, 833.0899999999999), (7, 1577.25), (1, 1858.0), (2, 2440.21), (6, 3803.04), (5, 4436.36), (10, 4909.76), (8, 4918.25), (9, 5205.0)]\n",
            "K Cluster Dictionary [(11, 680.69), (4, 720.36), (3, 763.61), (0, 833.0899999999999), (7, 1577.25)]\n",
            "Retrieved K Distances [680.69, 720.36, 763.61, 833.0899999999999, 1577.25]\n",
            "Final_Weight: [0.24479953769771534, 0.23131850368629275, 0.2182168873056375, 0.20001752189494276, 0.10564754941541156]\n",
            "-----------------------------------------------------------------------------------------\n",
            "Final Imputed value: 0.395\n",
            "-----------------------------------------------------------------------------------------\n",
            "Distance Before Sort: [1986.0, 325.0899999999999, 1345.8400000000001, 3374.04, 2865.29, 1207.29, 1036.25, 1736.8400000000001, 1228.84, 1676.69, 1434.49, 2122.16, 1573.8899999999999]\n",
            "Sorted Dictionary [(1, 325.0899999999999), (6, 1036.25), (5, 1207.29), (8, 1228.84), (2, 1345.8400000000001), (10, 1434.49), (12, 1573.8899999999999), (9, 1676.69), (7, 1736.8400000000001), (0, 1986.0), (11, 2122.16), (4, 2865.29), (3, 3374.04)]\n",
            "K Cluster Dictionary [(1, 325.0899999999999), (6, 1036.25), (5, 1207.29), (8, 1228.84), (2, 1345.8400000000001)]\n",
            "Retrieved K Distances [325.0899999999999, 1036.25, 1207.29, 1228.84, 1345.8400000000001]\n",
            "Final_Weight: [0.47867679473311864, 0.1501693985040188, 0.12889449858757177, 0.12663409329106273, 0.11562521488422806]\n",
            "-----------------------------------------------------------------------------------------\n",
            "Final Imputed value: 0.572\n",
            "-----------------------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------\n",
            "Final Imputed Dataset:\n",
            "      NTP     PG   DBP  TSFT  2HS1   BMI   AGE    DPF\n",
            "1    6.0  148.0  72.0  35.0  67.0  33.6  50.0  0.395\n",
            "2    1.0  153.0  90.0  31.0  62.0  43.3  32.0  0.372\n",
            "3    1.0   85.0  66.0  29.0  94.0  26.6  31.0  0.602\n",
            "4    4.0  137.0  40.0  35.0  60.0  43.1  33.0  0.407\n",
            "5    5.0  116.0  74.0  21.0  80.0  25.6  30.0  0.588\n",
            "6    1.0   89.0  66.0  23.0  86.0  28.1  21.0  0.599\n",
            "7    2.0  117.0  48.0  35.0  45.0  42.5  32.0  0.348\n",
            "8   11.0  145.0  96.0  33.0  74.0  34.9  54.0  0.430\n",
            "9    3.0  157.0  92.0  34.0  55.0  40.5  59.0  0.501\n",
            "10  10.0  115.0  72.0  31.0  70.0  35.3  29.0  0.572\n",
            "11  10.0  168.0  74.0  35.0  72.0  38.0  34.0  0.272\n",
            "12   4.0   88.0  74.0  25.0  88.0  28.0  34.0  0.537\n",
            "13   3.0   88.0  50.0  32.0  82.0  31.0  26.0  0.618\n",
            "14   5.0   96.0  62.0  28.0  90.0  23.8  32.0  0.698\n",
            "------------------------------------------------------------------------\n",
            "------------------------------------------------------------------------\n",
            "Completed\n"
          ]
        }
      ],
      "source": [
        "##Order Imputed Sequential KNN \n",
        "##Creating a null empty array equal to the dataset size\n",
        "dataset_array = dataset_1.to_numpy()\n",
        "print(\"Dataset Converted into a Numpy Array:\\n\",dataset_array)\n",
        "#imputed_data = np.zeros([len(dataset_1),len(dataset_1.columns)])\n",
        "imputed_data = np.zeros_like(dataset_array)\n",
        "print(\"\\nZeroes Array\\n\",imputed_data)\n",
        "#Creating Empty lists \n",
        "complete = []\n",
        "incompleted = []\n",
        "missing =[]\n",
        "com_ind=[]\n",
        "incomp_ind=[]\n",
        "##Taking the rows and cols of the input dataset for iteration purpose\n",
        "[rows,cols] = dataset_array.shape\n",
        "print(\"\\nNo of Rows are\",rows)\n",
        "print(\"No of Cols are\",cols)\n",
        "##iterating through the number of rows\n",
        "for i in range(len(dataset_array)):\n",
        "  a = dataset_array[i]\n",
        "  #print(\"Row is \",a)\n",
        "  nan_checker = np.sum(np.sum(a, axis=0))\n",
        "  #print(\"Sum of Row is\",nan_checker)\n",
        "  if math.isnan(nan_checker) :\n",
        "    #print(\"Spotted Nan Value - \",nan_checker)\n",
        "    incompleted.append(a)\n",
        "    incomp_ind.append(i+1)\n",
        "    #print(\"Non Sum of non numbers\",np.nansum(np.nansum(a, axis=0)))\n",
        "  else:\n",
        "    complete.append(a)\n",
        "    com_ind.append(i+1)\n",
        "zipped_com = zip(com_ind,complete)\n",
        "dict_complete = dict(zipped_com)\n",
        "##Ordering the list as per imputation order generated from Greedy\n",
        "zipped_incom = zip(incomp_ind,incompleted)\n",
        "dict_incompleted = dict(zipped_incom)\n",
        "print(dict_incompleted)\n",
        "sorted_incomplete =[(v,dict_incompleted[v]) for v in final_greedy_impute]\n",
        "print(sorted_incomplete)\n",
        "incom_ind = []\n",
        "incomplete = []\n",
        "for header in range(len(sorted_incomplete)):\n",
        "  header_app = sorted_incomplete[header][0]\n",
        "  value_app = sorted_incomplete[header][1]\n",
        "  incom_ind.append(header_app)\n",
        "  incomplete.append(value_app)\n",
        "print(incom_ind)\n",
        "print(incomplete)\n",
        "incom_ind_1 = sorted_incomplete[0][0]\n",
        "print(incom_ind_1)\n",
        "for i in com_ind:\n",
        "  imputed_data[i-1] = dict_complete[i]\n",
        "print(\"Imputed Data After Filling the Complete Rows:\\n\",imputed_data)\n",
        "print(\"Incomplete Rows in the Array\\n\",incomplete)\n",
        "\n",
        "for k in incomplete:\n",
        "  #print(k)\n",
        "  dist = []\n",
        "  cgen = len(complete)\n",
        "  for j in range(cgen):\n",
        "    #print(k)\n",
        "    #print(\"j\",j)\n",
        "    #print(complete[j])\n",
        "    d = np.nansum(np.power(([k]-complete[j]),2))\n",
        "    dist.append(d)\n",
        "  print(\"Distance Before Sort:\",dist)  \n",
        "  position=[]\n",
        "  for l in range(len(dist)):\n",
        "    position.append(l)\n",
        "  zipped_pos = zip(position,dist)\n",
        "  dict_pos = dict(zipped_pos)\n",
        "  #print(dict_pos)\n",
        "  from operator import itemgetter  \n",
        "  dict_pos_sorted =  sorted(dict_pos.items(), key = itemgetter(1), reverse = False)\n",
        "  print(\"Sorted Dictionary\",dict_pos_sorted)\n",
        "  K = 5\n",
        "  cluster_dictionary = dict_pos_sorted[:5]\n",
        "  print(\"K Cluster Dictionary\",cluster_dictionary)\n",
        "  k_dist = []\n",
        "  k_weight = []\n",
        "  k_final_weight = []\n",
        "  for d,s in cluster_dictionary:\n",
        "    k_dist.append(s)\n",
        "  print(\"Retrieved K Distances\",k_dist)\n",
        "  #total_list_sum = sum(1/((k_dist)))\n",
        "  #print(total_list_sum)\n",
        "  for h in range(len(k_dist)):\n",
        "    #weight = np.true_divide((1/k_dist[h]),)\n",
        "    individual_weight = ((1/k_dist[h]))\n",
        "    k_weight.append(individual_weight)\n",
        "  for u in k_weight:\n",
        "    final_weight = np.true_divide(u,sum(k_weight))\n",
        "    k_final_weight.append(final_weight)\n",
        "  #print(\"K Weight:\",k_weight)   \n",
        "  print(\"Final_Weight:\",k_final_weight)\n",
        "  #print(complete)\n",
        "  for a in range(np.size(dataset_array,1)):\n",
        "      complete_values_list =[] \n",
        "      column_value = k[a]\n",
        "      if math.isnan(column_value):\n",
        "        for o,p in cluster_dictionary:\n",
        "          complete_value = complete[o][a]\n",
        "          complete_values_list.append(complete_value)\n",
        "        #print(\"Complete_value\",complete_values_list)\n",
        "        imputed_final_value = round(sum(f * e for f, e in zip(complete_values_list,k_final_weight)),3)\n",
        "        print(\"-----------------------------------------------------------------------------------------\")\n",
        "        print(\"Final Imputed value:\",imputed_final_value) \n",
        "        print(\"-----------------------------------------------------------------------------------------\")\n",
        "        k[a] = imputed_final_value\n",
        "  complete.append(k)\n",
        "incomplete_dataframe = pd.DataFrame(incomplete)\n",
        "incomplete_dataframe['ind'] = incom_ind\n",
        "incomplete_dataframe.set_index('ind',inplace=True)\n",
        "imputed_data_frame = pd.DataFrame(imputed_data)\n",
        "imputed_data_frame.index = imputed_data_frame.index+1\n",
        "final_imputed_df = incomplete_dataframe.combine_first(imputed_data_frame)\n",
        "final_imputed_df.columns = dataset_1.columns\n",
        "print(\"------------------------------------------------------------------------\")\n",
        "print(\"------------------------------------------------------------------------\")\n",
        "print(\"Final Imputed Dataset:\\n\", final_imputed_df)\n",
        "print(\"------------------------------------------------------------------------\")\n",
        "print(\"------------------------------------------------------------------------\")\n",
        "print(\"Completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "mv-centered graph",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
